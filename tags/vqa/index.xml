<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>vqa on Jonathan`s Blog</title>
    <link>http://jonathanwayy.xyz/tags/vqa/</link>
    <description>Recent content in vqa on Jonathan`s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <copyright>All rights reserved - 2020</copyright>
    <lastBuildDate>Fri, 28 May 2021 19:43:09 +0800</lastBuildDate><atom:link href="http://jonathanwayy.xyz/tags/vqa/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>[论文阅读笔记 -- VQA] Learnable Aggregating Net with Diversity Learning (MM 2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn5/</link>
      <pubDate>Fri, 28 May 2021 19:43:09 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn5/</guid>
      <description>Learnable Aggregating Net with Diversity Learning for Video Question Answering (MM 2019) V-VQA 三个难点 视频通常包含大量冗余信息 一些视频相关问题涉及多个关键帧，较难定位 有效聚合视频与句子特征以捕捉回答真实分布的</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- VQA] Structured Two-stream Attention Network (AAAI 2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn4/</link>
      <pubDate>Fri, 28 May 2021 15:21:20 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn4/</guid>
      <description>Structured two-stream attention network for video question answering (AAAI 2019) 图像 QA 中两种注意力机制 visual attention: &amp;ldquo;where to look&amp;rdquo; question attention: &amp;ldquo;what words to listen to&amp;rdquo; 视频 QA 三个主要困难 考虑长距离时域结构，同时不遗漏重要信息 为了定位相关视频实</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- VQA] Motion-Appearance Co-Memory Networks (CVPR 2018)</title>
      <link>http://jonathanwayy.xyz/2021/prn3/</link>
      <pubDate>Fri, 28 May 2021 14:06:27 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn3/</guid>
      <description>Motion-Appearance Co-Memory Networks for Video Question Answering (CVPR 2018) 视频 QA 与 图像 QA 相比三个独有特性 处理较长的图像序列，包含更丰富的信息（数量上及多样性上） 动作与外观信息通常互相关联，能够彼此</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- VQA] Gradually Refined Attention (MM 2017)</title>
      <link>http://jonathanwayy.xyz/2021/prn2/</link>
      <pubDate>Thu, 27 May 2021 13:55:03 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn2/</guid>
      <description>Video Question Answering via Gradually Refined Attention over Appearance and Motion (MM17) 延伸模型的缺陷 由 video captioning 与 ImageQA 等任务延伸而来的模型容易弱化或忽视视频的时域信息 这些模型将整个问题编码为单一特征，不具有足够</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- VQA] TGIF-QA (CVPR 2017)</title>
      <link>http://jonathanwayy.xyz/2021/prn1/</link>
      <pubDate>Thu, 27 May 2021 13:49:47 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn1/</guid>
      <description>Tgif-qa: Toward spatio-temporal reasoning in visual question answering (CVPR 2017) 开源代码传送门 三点重要贡献 提出专为视频 VQA 设计的三种新任务，需要对视频的时空推断(spatio-temporal reaso</description>
    </item>
    
  </channel>
</rss>
